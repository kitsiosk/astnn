{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8913935b-540d-4f62-b592-1ea97eb72feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konstantinos/Desktop/virtualenvs/astnn/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from model_siamese import BatchProgramCC\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fec29e-9ea0-4f72-97d2-9bac86696b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53f806b-fd81-4e52-bd97-1b2311b9babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"trainBCBtestSCB\" # \"trainSCBtestBCB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2e709-1c11-4470-9bdb-7336cb04688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc54d5b1-93c8-4941-ada4-79cd1483f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset, idx, bs):\n",
    "    tmp = dataset.iloc[idx: idx+bs]\n",
    "    x1, x2, labels = [], [], []\n",
    "    for _, item in tmp.iterrows():\n",
    "        x1.append(item['code_x'])\n",
    "        x2.append(item['code_y'])\n",
    "        labels.append([item['label']])\n",
    "    return x1, x2, torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af22cbef-9ae5-4867-a691-6a09a15fab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive loss function\n",
    "def contrastive_loss(embedding1, embedding2, label, margin=1.0):\n",
    "    distance = torch.nn.functional.pairwise_distance(embedding1, embedding2)\n",
    "\n",
    "    loss = torch.mean((1 - label) * 0.5 * torch.pow(distance, 2) +\n",
    "                      label * 0.5 * torch.pow(torch.clamp(margin - distance, min=0.0), 2))\n",
    "    #print(distance) # Should not vanish to zero\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdbb258-af4a-41ea-a0b2-f7e76aeac23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ab19fe-76fb-4c68-9e56-9c49d185ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/'\n",
    "lang = 'java'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3819912f-af84-4c52-aed3-e2b90e0039c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scb = pd.read_pickle(root+lang+'/scb/blocks.pickle').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926f857d-10b2-491b-85ff-e4567353009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scb['label'] = 1 - data_scb['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4f75c7-c5ff-42a8-907a-f82209e09198",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(root+lang+\"/scb/embedding/node_w2v_128\").wv\n",
    "MAX_TOKENS = word2vec.vectors.shape[0]\n",
    "EMBEDDING_DIM = word2vec.vectors.shape[1]\n",
    "embeddings = np.zeros((MAX_TOKENS + 1, EMBEDDING_DIM), dtype=\"float32\")\n",
    "embeddings[:word2vec.vectors.shape[0]] = word2vec.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718cbe07-7444-4ced-bec3-5513c5b9d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 100\n",
    "ENCODE_DIM = 128\n",
    "LABELS = 1\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21c1999-7295-456a-95b8-663e77038846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    19523\n",
       "1    19533\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scb.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb2e47b9-687e-4049-a61c-e6a344877c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BatchProgramCC(EMBEDDING_DIM,HIDDEN_DIM,MAX_TOKENS+1,ENCODE_DIM,LABELS,BATCH_SIZE,\n",
    "                            USE_GPU, embeddings)\n",
    "if USE_GPU:\n",
    "    model.cuda()\n",
    "\n",
    "parameters = model.parameters()\n",
    "#optimizer = torch.optim.Adamax(parameters, lr=0.0001)\n",
    "optimizer = torch.optim.Adam(parameters, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38065fa1-5746-4f23-a7ec-4cd50b57eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_data_t):\n",
    "    model.eval()\n",
    "    similarity_scores = []\n",
    "    trues = []\n",
    "    iTest = 0\n",
    "    \n",
    "    while iTest < len(test_data_t):\n",
    "        batch = get_batch(test_data_t, iTest, BATCH_SIZE)\n",
    "        iTest += BATCH_SIZE\n",
    "        test1_inputs, test2_inputs, test_labels = batch\n",
    "        if USE_GPU:\n",
    "            test_labels = test_labels.cuda()\n",
    "    \n",
    "        model.batch_size = len(test_labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "        with torch.no_grad():\n",
    "            embeddings1 = model(test1_inputs)\n",
    "            embeddings2 = model(test2_inputs)\n",
    "        similarity_score = torch.nn.functional.cosine_similarity(embeddings1, embeddings2)\n",
    "    \n",
    "        loss = contrastive_loss(embeddings1, embeddings2, Variable(test_labels), margin=margin)\n",
    "    \n",
    "        # calc testing acc\n",
    "        similarity_scores.extend(similarity_score.cpu())\n",
    "        trues.extend(1 - test_labels.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    trues = np.array(trues)\n",
    "    \n",
    "\n",
    "\n",
    "    max_Acc = -np.inf\n",
    "    for similarity_threshold_int in range(-5, 10):\n",
    "        similarity_threshold = similarity_threshold_int/10\n",
    "        # Classify code pairs based on the similarity score and threshold\n",
    "        predicted_labels = (np.array(similarity_scores) > similarity_threshold)\n",
    "        acc = 1-np.sum(np.abs(predicted_labels-np.transpose(trues)))/trues.shape[0]\n",
    "        P, R, F1, _ = precision_recall_fscore_support(predicted_labels, trues, average='binary', pos_label=1)\n",
    "    \n",
    "    \n",
    "        if acc > max_Acc:\n",
    "            max_Acc = acc\n",
    "            best_similarity_threshold = similarity_threshold\n",
    "\n",
    "    predicted_labels = np.array(similarity_scores) > best_similarity_threshold\n",
    "    p, r, f, _ = precision_recall_fscore_support(trues, predicted_labels, average='binary')\n",
    "    acc = 1-np.sum(np.abs(predicted_labels-np.transpose(trues)))/trues.shape[0]\n",
    "    print(\"F1=%.3f, P=%.3f, R=%.3f, A=%.3f for similarity threshold %0.2f\" % (f, p, r, acc, best_similarity_threshold))\n",
    "\n",
    "\n",
    "    max_F1 = -np.inf\n",
    "    for similarity_threshold_int in range(-5, 10):\n",
    "        similarity_threshold = similarity_threshold_int/10\n",
    "        # Classify code pairs based on the similarity score and threshold\n",
    "        predicted_labels = (np.array(similarity_scores) > similarity_threshold)\n",
    "        acc = 1-np.sum(np.abs(predicted_labels-np.transpose(trues)))/trues.shape[0]\n",
    "        P, R, F1, _ = precision_recall_fscore_support(predicted_labels, trues, average='binary', pos_label=1)\n",
    "    \n",
    "    \n",
    "        if F1 > max_F1:\n",
    "            max_F1 = F1\n",
    "            best_similarity_threshold = similarity_threshold\n",
    "            \n",
    "    predicted_labels = np.array(similarity_scores) > best_similarity_threshold\n",
    "    p, r, f, _ = precision_recall_fscore_support(trues, predicted_labels, average='binary')\n",
    "    acc = 1-np.sum(np.abs(predicted_labels-np.transpose(trues)))/trues.shape[0]\n",
    "    print(\"F1=%.3f, P=%.3f, R=%.3f, A=%.3f for similarity threshold %0.2f\" % (f, p, r, acc, best_similarity_threshold))\n",
    "\n",
    "\n",
    "    sys.stdout.flush()\n",
    "    model.train()\n",
    "    return f, similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f04d96-4d70-473a-99dd-6db53146af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"trainBCBtestSCB\":\n",
    "    data_train = data_scb[~data_scb['functionality_id'].isna()]\n",
    "    \n",
    "    data_test = data_scb[data_scb['functionality_id'].isna()]\n",
    "else:\n",
    "    data_train = data_scb[data_scb['functionality_id'].isna()]\n",
    "    \n",
    "    data_test = data_scb[~data_scb['functionality_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0755ed8-aac8-497d-a0e3-bfb50246ab6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f669f6-174a-4c7d-ae7e-fa51f28187e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b36b19c-1818-4a72-a2b2-8245275d3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_epoch_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867724da-37fe-49d3-b938-5aaa6bef1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    loss_arr_train = []\n",
    "    i = 0\n",
    "    while i < len(data_train):\n",
    "        model.train()\n",
    "        batch = get_batch(data_train, i, BATCH_SIZE)\n",
    "        train1_inputs, train2_inputs, train_labels = batch\n",
    "        if USE_GPU:\n",
    "            train1_inputs, train2_inputs, train_labels = train1_inputs, train2_inputs, train_labels.cuda()\n",
    "    \n",
    "        model.zero_grad()\n",
    "        model.batch_size = len(train_labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "    \n",
    "        embeddings1 = model(train1_inputs)\n",
    "        embeddings2 = model(train2_inputs)\n",
    "    \n",
    "        loss = contrastive_loss(embeddings1, embeddings2, Variable(train_labels), margin=margin)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        loss_arr_train.append(loss.detach().numpy())\n",
    "        if ((i/BATCH_SIZE) % 50 == 0) and False:\n",
    "            print(i/BATCH_SIZE)\n",
    "            print(loss.detach().numpy())\n",
    "            t1 = torch.nn.functional.pairwise_distance(embeddings1, embeddings2).detach().numpy()\n",
    "            t2 = train_labels.cpu()\n",
    "\n",
    "            idx_clones = (t2 == 0).squeeze()\n",
    "            idx_non_clones = (t2 == 1).squeeze()\n",
    "            print(\"Clones:\")\n",
    "            print(t1[idx_clones])\n",
    "            print(t1[idx_clones].mean())\n",
    "            print(\"Non clones:\")\n",
    "            print(t1[idx_non_clones])\n",
    "            print(t1[idx_non_clones].mean())\n",
    "\n",
    "            f, similarity_scores = eval_model(model, data_test)\n",
    "            print()\n",
    "        i += BATCH_SIZE\n",
    "\n",
    "    \n",
    "    f, similarity_scores = eval_model(model, data_test)\n",
    "\n",
    "    if f<prev_epoch_f1:\n",
    "        print(\"Lower F1 than previous epoch. Early stopping...\")\n",
    "        sys.stdout.flush()\n",
    "        break\n",
    "    else:\n",
    "        prev_epoch_f1 = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15b016-3994-4b47-ba61-a89680355abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab7341-1433-4ae9-84fa-2febc5656e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d00d4-1c4b-450a-8403-09ff2ced9ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67991aea-f787-4801-943c-ec242dd159d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045030b-c2eb-4ec3-b452-e7df420af989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cbd51-cfd1-49b2-b0a3-8605a0f510d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
